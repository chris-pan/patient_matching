{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fuzzy\n",
    "import datetime\n",
    "import re\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_in = pd.read_excel('FILE DESTINATION') or pd.read_csv('FILE DESTINATION')\n",
    "#if reading in another file to be used for testing\n",
    "#Can use other csv/excel files for training as well (replace cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change destination to whereever the provided Patient Matching Data is stored\n",
    "df = pd.read_excel('/Users/christopherpan 1/Desktop/LAHacks/Patient Matching Data.xlsx',sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.loc[:, ['GroupID', 'First Name', 'Last Name', 'Date of Birth', 'Sex', \n",
    "                  'Current Street 1', 'Current Street 2', 'Current Zip Code']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chose to use first name, last name, DOB, sex, and address (st 1 + st 2 + zip code)\n",
    "#converted names to soundex tokens\n",
    "#stemmed and lemmatized address\n",
    "soundex = fuzzy.Soundex(4)\n",
    "stemmer = PorterStemmer()\n",
    "for row in arr:\n",
    "    if isinstance(row[2], str):\n",
    "        row[1] = soundex(row[1].lower())\n",
    "        row[2] = soundex(row[2].lower())\n",
    "    else:\n",
    "        row[1] = soundex(row[1].lower())\n",
    "    row[1] = row[1].replace('%d','')\n",
    "    if isinstance(row[3], datetime.datetime):\n",
    "        row[3] = row[3].strftime(\"%m/%d/%Y\")\n",
    "    if isinstance(row[4], str):\n",
    "        row[4] = row[4][0]\n",
    "    else:\n",
    "        row[4] = 'U'\n",
    "    if isinstance(row[5], str):\n",
    "        row[5] = word_tokenize(row[5])\n",
    "        str_lst = list(row[5])\n",
    "        for i in range(len(str_lst)):\n",
    "            str_lst[i] = stemmer.stem(str_lst[i])\n",
    "        row[5] = \"\".join(str_lst)\n",
    "        if isinstance(row[6], str):\n",
    "            row[6] = word_tokenize(row[6])\n",
    "            str_lst = list(row[6])\n",
    "            for i in range(len(str_lst)):\n",
    "                str_lst[i] = stemmer.stem(str_lst[i])\n",
    "            row[6] = \"\".join(str_lst)\n",
    "            row[5] += row[6]\n",
    "        if not math.isnan(row[7]):\n",
    "            row[5] += str(int(float(row[7])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_desired = np.delete(arr, [6, 7], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates data to be used for training by comparing each person with others\n",
    "def create(arr, groups, total):\n",
    "    if len(groups) == 0:\n",
    "        groups.append(compare(arr, arr))\n",
    "        return\n",
    "    add = []\n",
    "    for lst in total:\n",
    "        add.append(compare(arr, lst))\n",
    "    groups.extend(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edit distance\n",
    "def levenshtein(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1 # j+1 instead of j since previous_row and current_row are one character longer\n",
    "            deletions = current_row[j] + 1       # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns array of comparisons\n",
    "def compare(arr, person):\n",
    "    first_name = levenshtein(arr[1], person[1])\n",
    "    first_other = levenshtein(arr[1], str(person[2]))\n",
    "    last_name = levenshtein(str(arr[2]), str(person[2]))\n",
    "    last_other = levenshtein(str(arr[2]), str(person[1]))\n",
    "    if first_other > first_name:\n",
    "        first_name = first_other\n",
    "        lsat_name = last_other\n",
    "    bday = levenshtein(str(arr[3]), str(person[3]))\n",
    "    gender = levenshtein(arr[4], person[4])\n",
    "    address = levenshtein(str(arr[5]), str(person[5]))  \n",
    "    same = 0 if arr[0] == person[0] else 1\n",
    "    return [first_name, last_name, bday, gender, address, same]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = []\n",
    "for row in arr_desired:\n",
    "    create(row, groups, arr_desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_groups = np.array(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np_groups[:,:5]\n",
    "y = np_groups[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#originally split into test and train split\n",
    "#after verifying accuracy swapped to using entire dataset for training\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 420)\n",
    "x_train, y_train = x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(arr, groups):\n",
    "    if len(groups) == 0:\n",
    "        groups[0] = [arr]\n",
    "        return\n",
    "    for key in groups:\n",
    "        add = []\n",
    "        for lst in groups[key]:\n",
    "            add.append(compare(arr, lst)[:5])\n",
    "        #originally used logistic regression instead of SVM\n",
    "        #Use of SVM could have lead to overfitting \n",
    "        #which would occur less in logistic regression model \n",
    "        #at the cost of accuracy\n",
    "        #log_n = logisticRegr.predict(np.array(add))\n",
    "        log_n = clf.predict(np.array(add))\n",
    "        if (log_n == 0).sum() > log_n.size/2:\n",
    "            groups[key].append(arr)\n",
    "            return\n",
    "    groups[len(groups)] = [arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(gamma = 'auto')\n",
    "clf.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_groups = {}\n",
    "for row in arr_desired:\n",
    "    match(row, svc_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1 1 1 \n",
      "2 2 \n",
      "3 3 3 3 3 3 \n",
      "4 4 \n",
      "5 5 5 5 \n",
      "6 \n",
      "7 7 7 \n",
      "8 8 8 \n",
      "9 9 \n",
      "10 10 \n",
      "11 11 11 11 \n",
      "12 13 \n",
      "14 \n",
      "15 15 15 \n",
      "16 \n",
      "17 17 17 17 \n",
      "18 18 \n",
      "19 19 19 19 \n",
      "20 20 20 20 20 \n",
      "21 21 21 21 \n",
      "22 \n",
      "23 23 23 23 23 23 \n",
      "24 24 \n",
      "25 25 25 25 25 \n",
      "26 26 26 26 \n",
      "27 27 27 27 27 \n",
      "28 28 28 \n",
      "29 29 29 29 29 29 \n",
      "30 30 \n",
      "31 31 31 31 31 \n",
      "32 32 32 \n",
      "33 33 33 33 \n",
      "34 34 \n",
      "35 35 35 35 35 \n",
      "36 \n",
      "37 37 37 37 \n",
      "38 38 38 \n",
      "39 39 39 39 39 \n",
      "40 40 40 \n",
      "41 41 41 41 \n",
      "42 42 42 \n",
      "42 \n",
      "43 43 43 43 43 43 \n",
      "44 44 44 \n",
      "45 45 45 45 \n",
      "46 46 46 46 \n",
      "47 47 47 47 \n",
      "48 48 48 \n",
      "49 49 49 49 \n",
      "50 \n",
      "51 51 \n",
      "52 52 52 \n",
      "53 53 53 53 \n",
      "54 54 54 \n",
      "55 55 55 55 \n",
      "56 \n",
      "57 57 57 \n",
      "58 58 58 58 \n",
      "59 59 59 59 \n",
      "60 60 \n",
      "61 \n",
      "62 \n",
      "63 \n",
      "64 65 \n"
     ]
    }
   ],
   "source": [
    "#printing grouping results (same #'s should be in a group)\n",
    "seen = {}\n",
    "for key in svc_groups:\n",
    "    for pp in svc_groups[key]:\n",
    "        print(pp[0], end =' ') \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_add = []\n",
    "for key in svc_groups:\n",
    "    for person in svc_groups[key]:\n",
    "        col_add.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_add = np.array(col_add)\n",
    "df.insert(1, 'Predicted GroupID', col_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change destination\n",
    "df.to_csv('/Users/christopherpan 1/Desktop/LAHacks/predicted_matches.csv', index = False, header = True)\n",
    "#can use df_in (the test/other data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
